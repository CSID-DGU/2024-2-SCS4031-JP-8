{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 블록 1: 임포트 및 기본 함수들\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rc('font', family='AppleGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 데이터 읽기\n",
    "base_path = '/Users/foxrainswap/Desktop/데이터/재차인원/1112/합본'\n",
    "train_data = pd.read_csv(os.path.join(base_path, '트레이닝셋_정규화x_이상치제거.csv'))\n",
    "test_data = pd.read_csv(os.path.join(base_path, '테스트셋_정규화x.csv'))\n",
    "\n",
    "# 날짜 변환\n",
    "train_data['날짜'] = pd.to_datetime(train_data['날짜'])\n",
    "test_data['날짜'] = pd.to_datetime(test_data['날짜'])\n",
    "\n",
    "def prepare_data(data):\n",
    "    \"\"\"데이터 전처리\"\"\"\n",
    "    time_columns = ['04시', '05시', '06시', '07시', '08시', '09시', '10시', \n",
    "                   '11시', '12시', '13시', '14시', '15시', '16시', '17시', \n",
    "                   '18시', '19시', '20시', '21시', '22시', '23시', '00시', \n",
    "                   '01시', '02시', '03시']\n",
    "    \n",
    "    melted_data = pd.melt(data, \n",
    "                         id_vars=['날짜', '정류장순번', '정류장명', '요일'], \n",
    "                         value_vars=time_columns,\n",
    "                         var_name='시간', \n",
    "                         value_name='재차인원')\n",
    "    \n",
    "    melted_data['datetime'] = pd.to_datetime(melted_data['날짜'].astype(str) + ' ' + \n",
    "                                           melted_data['시간'].str.replace('시', ':00'))\n",
    "    \n",
    "    # 평일/토요일/일요일 구분\n",
    "    melted_data['요일구분'] = melted_data['요일'].map({\n",
    "        '토요일': '토요일',\n",
    "        '일요일': '일요일'\n",
    "    }).fillna('평일')\n",
    "    \n",
    "    melted_data.sort_values(['정류장순번', 'datetime'], inplace=True)\n",
    "    \n",
    "    return melted_data\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"시계열 데이터를 시퀀스로 변환\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:(i + seq_length)])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def create_lstm_model(seq_length):\n",
    "    \"\"\"LSTM 모델 생성\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(100, activation='relu', input_shape=(seq_length, 1), return_sequences=True),\n",
    "        LSTM(50, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "def post_process_predictions(predictions):\n",
    "    \"\"\"예측값 후처리\"\"\"\n",
    "    processed = predictions.copy()\n",
    "    processed[processed < 1] = 0  # 1미만 값을 0으로\n",
    "    processed[processed < 0] = 0  # 음수 값을 0으로\n",
    "    return processed\n",
    "\n",
    "def calculate_evaluation_metrics(y_true, y_pred):\n",
    "    \"\"\"평가 지표 계산\"\"\"\n",
    "    # 1. 먼저 예측값 후처리 (음수, 0~1 사이 값을 0으로)\n",
    "    processed_pred = post_process_predictions(y_pred)\n",
    "    \n",
    "    # 2. 기본 지표 계산\n",
    "    mae = mean_absolute_error(y_true, processed_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, processed_pred))\n",
    "    \n",
    "    # 3. SMAPE 계산\n",
    "    # - 후처리된 예측값(processed_pred)을 사용\n",
    "    # - 실제값과 후처리된 예측값이 모두 0인 경우는 정확히 맞춘 것으로 처리\n",
    "    numerator = np.abs(y_true - processed_pred)\n",
    "    denominator = np.abs(y_true) + np.abs(processed_pred)\n",
    "    \n",
    "    zero_mask = denominator == 0\n",
    "    smape = np.mean(\n",
    "        np.where(zero_mask, 0, numerator / denominator)\n",
    "    ) * 200\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': 0,  # 사용하지 않을 MAPE\n",
    "        'SMAPE': smape\n",
    "    }\n",
    "\n",
    "def convert_predictions_to_daily(predictions, test_station, time_columns):\n",
    "    \"\"\"예측값을 날짜별로 변환\"\"\"\n",
    "    n_days = len(predictions) // len(time_columns)\n",
    "    daily_predictions = predictions[:n_days * len(time_columns)].reshape(n_days, len(time_columns))\n",
    "    return daily_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 블록 2: plot_learning_curves 함수와 analyze_all_stations 함수\n",
    "\n",
    "def plot_learning_curves(history, station_id, station_name, day_type):\n",
    "   \"\"\"학습 곡선 그리기\"\"\"\n",
    "   plt.figure(figsize=(10, 6))\n",
    "   plt.plot(history.history['loss'], label='Training Loss')\n",
    "   plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "   plt.title(f'정류장 {station_id} ({station_name}) - {day_type}\\n학습 곡선')\n",
    "   plt.xlabel('Epoch')\n",
    "   plt.ylabel('Loss')\n",
    "   plt.legend()\n",
    "   plt.grid(True)\n",
    "   plt.tight_layout()\n",
    "   \n",
    "   # 그래프 저장\n",
    "   save_dir = 'learning_curves'\n",
    "   if not os.path.exists(save_dir):\n",
    "       os.makedirs(save_dir)\n",
    "   plt.savefig(f'{save_dir}/learning_curve_station_{station_id}_{day_type}.png')\n",
    "   plt.close()\n",
    "\n",
    "def analyze_all_stations(train_data, test_data, seq_length=24):\n",
    "   \"\"\"모든 정류장에 대한 LSTM 분석 수행\"\"\"\n",
    "   time_columns = ['04시', '05시', '06시', '07시', '08시', '09시', '10시', \n",
    "                  '11시', '12시', '13시', '14시', '15시', '16시', '17시', \n",
    "                  '18시', '19시', '20시', '21시', '22시', '23시', '00시', \n",
    "                  '01시', '02시', '03시']\n",
    "   \n",
    "   # 운행 시간대 정의\n",
    "   operating_hours = ['04시','05시','06시','07시','08시','09시','10시','11시','12시', '13시', '14시', '15시', '16시', '17시', \n",
    "                  '18시', '19시', '20시', '21시', '22시', '23시', '00시']\n",
    "   \n",
    "   # 첨두시간대 정의\n",
    "   peak_hours = ['17시', '18시', '19시', '07시', '08시','09시']\n",
    "   \n",
    "   # 시간대 인덱스 구하기\n",
    "   operating_idx = [time_columns.index(h) for h in operating_hours]\n",
    "   peak_idx = [time_columns.index(h) for h in peak_hours]\n",
    "   \n",
    "   prepared_train = prepare_data(train_data)\n",
    "   prepared_test = prepare_data(test_data)\n",
    "   \n",
    "   # Early Stopping 설정\n",
    "   early_stopping = EarlyStopping(\n",
    "       monitor='val_loss',\n",
    "       patience=20,\n",
    "       restore_best_weights=True,\n",
    "       verbose=0\n",
    "   )\n",
    "   \n",
    "   weekday_results = []\n",
    "   saturday_results = []\n",
    "   sunday_results = []\n",
    "   evaluation_results = []\n",
    "   \n",
    "   all_stations = train_data['정류장순번'].unique()\n",
    "   total_stations = len(all_stations)\n",
    "\n",
    "   for idx, station_id in enumerate(all_stations, 1):\n",
    "       print(f\"\\n정류장 처리 중... ({idx}/{total_stations})\")\n",
    "       station_name = train_data[train_data['정류장순번'] == station_id]['정류장명'].iloc[0]\n",
    "       \n",
    "       for day_type in ['평일', '토요일', '일요일']:\n",
    "           try:\n",
    "               # 데이터 준비\n",
    "               train_station = prepared_train[\n",
    "                   (prepared_train['요일구분'] == day_type) & \n",
    "                   (prepared_train['정류장순번'] == station_id)\n",
    "               ].sort_values('datetime').reset_index(drop=True)\n",
    "               \n",
    "               test_station = prepared_test[\n",
    "                   (prepared_test['요일구분'] == day_type) & \n",
    "                   (prepared_test['정류장순번'] == station_id)\n",
    "               ].sort_values('datetime').reset_index(drop=True)\n",
    "               \n",
    "               # 시퀀스 생성\n",
    "               train_values = train_station['재차인원'].values.reshape(-1, 1)\n",
    "               test_values = test_station['재차인원'].values.reshape(-1, 1)\n",
    "               X_train, y_train = create_sequences(train_values, seq_length)\n",
    "               X_test, y_test = create_sequences(test_values, seq_length)\n",
    "               \n",
    "               # LSTM 모델 생성 및 학습\n",
    "               model = create_lstm_model(seq_length)\n",
    "               history = model.fit(\n",
    "                   X_train, y_train,\n",
    "                   epochs=100,\n",
    "                   batch_size=32,\n",
    "                   validation_split=0.2,\n",
    "                   callbacks=[early_stopping],\n",
    "                   verbose=0\n",
    "               )\n",
    "               \n",
    "               # 학습 곡선 그리기\n",
    "               plot_learning_curves(history, station_id, station_name, day_type)\n",
    "               \n",
    "               # Early Stopping으로 실제 학습된 epoch 수 출력\n",
    "               epochs_trained = len(history.history['loss'])\n",
    "               print(f\"Epochs trained: {epochs_trained}\")\n",
    "               \n",
    "               # 예측\n",
    "               predictions = model.predict(X_test, verbose=0).flatten()\n",
    "               \n",
    "               # 예측값을 날짜별로 변환\n",
    "               daily_predictions = convert_predictions_to_daily(predictions, test_station, time_columns)\n",
    "               \n",
    "               # 평균 일일 예측값 계산\n",
    "               avg_predictions = np.mean(daily_predictions, axis=0)\n",
    "               \n",
    "               # 결과 저장\n",
    "               result_dict = {\n",
    "                   '정류장순번': station_id,\n",
    "                   '정류장명': station_name\n",
    "               }\n",
    "               for time, pred in zip(time_columns, avg_predictions):\n",
    "                   result_dict[time] = pred if time in operating_hours else 0\n",
    "               \n",
    "               # 요일별 결과 저장\n",
    "               if day_type == '평일':\n",
    "                   weekday_results.append(result_dict)\n",
    "               elif day_type == '토요일':\n",
    "                   saturday_results.append(result_dict)\n",
    "               else:  # 일요일\n",
    "                   sunday_results.append(result_dict)\n",
    "               \n",
    "               # 평가 데이터 준비\n",
    "               test_values_reshaped = test_values[:len(predictions)].reshape(-1)\n",
    "               \n",
    "               # 운영시간대 평가\n",
    "               operating_mask = np.array([i % len(time_columns) in operating_idx for i in range(len(predictions))])\n",
    "               operating_predictions = predictions[operating_mask]\n",
    "               operating_actual = test_values_reshaped[operating_mask]\n",
    "               \n",
    "               # 첨두시간대 평가\n",
    "               peak_mask = np.array([i % len(time_columns) in peak_idx for i in range(len(predictions))])\n",
    "               peak_predictions = predictions[peak_mask]\n",
    "               peak_actual = test_values_reshaped[peak_mask]\n",
    "               \n",
    "               # 전체 시간대 평가\n",
    "               operating_metrics = calculate_evaluation_metrics(operating_actual, operating_predictions)\n",
    "               evaluation_results.append({\n",
    "                   '정류장순번': station_id,\n",
    "                   '정류장명': station_name,\n",
    "                   '요일구분': day_type,\n",
    "                   '구분': '전체',\n",
    "                   **operating_metrics\n",
    "               })\n",
    "               \n",
    "               # 첨두시간대 평가\n",
    "               peak_metrics = calculate_evaluation_metrics(peak_actual, peak_predictions)\n",
    "               evaluation_results.append({\n",
    "                   '정류장순번': station_id,\n",
    "                   '정류장명': station_name,\n",
    "                   '요일구분': day_type,\n",
    "                   '구분': '첨두',\n",
    "                   **peak_metrics\n",
    "               })\n",
    "               \n",
    "           except Exception as e:\n",
    "               print(f\"오류 발생 - 정류장: {station_id}, 구분: {day_type}\")\n",
    "               print(f\"오류 내용: {str(e)}\")\n",
    "               continue\n",
    "   \n",
    "   # 결과를 DataFrame으로 변환\n",
    "   weekday_df = pd.DataFrame(weekday_results)\n",
    "   saturday_df = pd.DataFrame(saturday_results)\n",
    "   sunday_df = pd.DataFrame(sunday_results)\n",
    "   evaluation_df = pd.DataFrame(evaluation_results)\n",
    "   \n",
    "   # 결과 저장\n",
    "   weekday_df.to_csv('lstm_predictions_weekday.csv', index=False)\n",
    "   saturday_df.to_csv('lstm_predictions_saturday.csv', index=False)\n",
    "   sunday_df.to_csv('lstm_predictions_sunday.csv', index=False)\n",
    "   evaluation_df.to_csv('lstm_evaluation.csv', index=False)\n",
    "   \n",
    "   return weekday_df, saturday_df, sunday_df, evaluation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM 모델 실행 중...\n",
      "\n",
      "정류장 처리 중... (1/52)\n",
      "Epochs trained: 22\n",
      "Epochs trained: 27\n",
      "Epochs trained: 36\n",
      "\n",
      "정류장 처리 중... (2/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (3/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (4/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (5/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (6/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (7/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (8/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (9/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (10/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (11/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (12/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (13/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (14/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (15/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (16/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (17/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (18/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (19/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (20/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (21/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (22/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (23/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (24/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (25/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (26/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (27/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (28/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (29/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (30/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (31/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (32/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (33/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (34/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (35/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (36/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (37/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (38/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (39/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (40/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (41/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (42/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (43/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (44/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (45/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (46/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (47/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (48/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (49/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (50/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "\n",
      "정류장 처리 중... (51/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 20\n",
      "Epochs trained: 23\n",
      "\n",
      "정류장 처리 중... (52/52)\n",
      "Epochs trained: 20\n",
      "Epochs trained: 21\n",
      "Epochs trained: 20\n",
      "\n",
      "분석 완료!\n",
      "결과 파일이 저장되었습니다:\n",
      "- lstm_predictions_weekday.csv\n",
      "- lstm_predictions_saturday.csv\n",
      "- lstm_predictions_sunday.csv\n",
      "- lstm_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "### 3번 블록: 실행 코드\n",
    "\n",
    "# 분석 실행\n",
    "print(\"\\nLSTM 모델 실행 중...\")\n",
    "weekday_df, saturday_df, sunday_df, evaluation_df = analyze_all_stations(train_data, test_data)\n",
    "\n",
    "print(\"\\n분석 완료!\")\n",
    "print(\"결과 파일이 저장되었습니다:\")\n",
    "print(\"- lstm_predictions_weekday.csv\")\n",
    "print(\"- lstm_predictions_saturday.csv\")\n",
    "print(\"- lstm_predictions_sunday.csv\")\n",
    "print(\"- lstm_evaluation.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
