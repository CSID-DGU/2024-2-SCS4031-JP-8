{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1번 블럭\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 데이터 읽기\n",
    "base_path = '/Users/foxrainswap/Desktop/데이터/재차인원/1112/합본'\n",
    "train_data = pd.read_csv(os.path.join(base_path, '트레이닝셋_정규화x_이상치제거.csv'))\n",
    "test_data = pd.read_csv(os.path.join(base_path, '테스트셋_정규화x.csv'))\n",
    "\n",
    "# 날짜 변환\n",
    "train_data['날짜'] = pd.to_datetime(train_data['날짜'])\n",
    "test_data['날짜'] = pd.to_datetime(test_data['날짜'])\n",
    "\n",
    "def prepare_data(data):\n",
    "    \"\"\"데이터 전처리\"\"\"\n",
    "    time_columns = ['04시', '05시', '06시', '07시', '08시', '09시', '10시', \n",
    "                   '11시', '12시', '13시', '14시', '15시', '16시', '17시', \n",
    "                   '18시', '19시', '20시', '21시', '22시', '23시', '00시', \n",
    "                   '01시', '02시', '03시']\n",
    "    \n",
    "    melted_data = pd.melt(data, \n",
    "                         id_vars=['날짜', '정류장순번', '정류장명', '요일'], \n",
    "                         value_vars=time_columns,\n",
    "                         var_name='시간', \n",
    "                         value_name='재차인원')\n",
    "    \n",
    "    melted_data['datetime'] = pd.to_datetime(melted_data['날짜'].astype(str) + ' ' + \n",
    "                                           melted_data['시간'].str.replace('시', ':00'))\n",
    "    \n",
    "    # 평일/토요일/일요일 구분\n",
    "    melted_data['요일구분'] = melted_data['요일'].map({\n",
    "        '토요일': '토요일',\n",
    "        '일요일': '일요일'\n",
    "    }).fillna('평일')\n",
    "    \n",
    "    melted_data.sort_values(['정류장순번', 'datetime'], inplace=True)\n",
    "    \n",
    "    return melted_data\n",
    "\n",
    "def post_process_predictions(predictions):\n",
    "    \"\"\"예측값 후처리\"\"\"\n",
    "    processed = predictions.copy()\n",
    "    processed[processed < 1] = 0  # 1미만 값을 0으로\n",
    "    processed[processed < 0] = 0  # 음수 값을 0으로\n",
    "    return processed\n",
    "\n",
    "def calculate_evaluation_metrics(y_true, y_pred):\n",
    "    \"\"\"평가 지표 계산\"\"\"\n",
    "    # 1. 먼저 예측값 후처리\n",
    "    processed_pred = post_process_predictions(y_pred)\n",
    "    \n",
    "    # 2. 기본 지표 계산\n",
    "    mae = mean_absolute_error(y_true, processed_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, processed_pred))\n",
    "    \n",
    "    # 3. SMAPE 계산\n",
    "    numerator = np.abs(y_true - processed_pred)\n",
    "    denominator = np.abs(y_true) + np.abs(processed_pred)\n",
    "    \n",
    "    zero_mask = denominator == 0\n",
    "    smape = np.mean(\n",
    "        np.where(zero_mask, 0, numerator / denominator)\n",
    "    ) * 200\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': 0,  # 사용하지 않을 MAPE\n",
    "        'SMAPE': smape\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2번 블록: analyze_all_stations 함수\n",
    "\n",
    "def analyze_all_stations(train_data, test_data):\n",
    "   \"\"\"모든 정류장에 대한 SARIMA 분석 수행\"\"\"\n",
    "   time_columns = ['04시', '05시', '06시', '07시', '08시', '09시', '10시', \n",
    "                  '11시', '12시', '13시', '14시', '15시', '16시', '17시', \n",
    "                  '18시', '19시', '20시', '21시', '22시', '23시', '00시', \n",
    "                  '01시', '02시', '03시']\n",
    "   \n",
    "   # 운행 시간대 정의\n",
    "   operating_hours = ['04시','05시','06시','07시','08시','09시','10시','11시','12시', '13시', '14시', '15시', '16시', '17시', \n",
    "                  '18시', '19시', '20시', '21시', '22시', '23시', '00시']\n",
    "   \n",
    "   # 첨두시간대 정의\n",
    "   peak_hours = ['17시', '18시', '19시', '07시', '08시','09시']\n",
    "   \n",
    "   prepared_train = prepare_data(train_data)\n",
    "   prepared_test = prepare_data(test_data)\n",
    "   \n",
    "   weekday_results = []\n",
    "   saturday_results = []\n",
    "   sunday_results = []\n",
    "   evaluation_results = []\n",
    "   \n",
    "   all_stations = train_data['정류장순번'].unique()\n",
    "   total_stations = len(all_stations)\n",
    "\n",
    "   for idx, station_id in enumerate(all_stations, 1):\n",
    "       print(f\"\\n정류장 처리 중... ({idx}/{total_stations})\")\n",
    "       station_name = train_data[train_data['정류장순번'] == station_id]['정류장명'].iloc[0]\n",
    "       \n",
    "       for day_type in ['평일', '토요일', '일요일']:\n",
    "           try:\n",
    "               # 데이터 준비\n",
    "               train_station = prepared_train[\n",
    "                   (prepared_train['요일구분'] == day_type) & \n",
    "                   (prepared_train['정류장순번'] == station_id)\n",
    "               ].sort_values('datetime').reset_index(drop=True)\n",
    "               \n",
    "               test_station = prepared_test[\n",
    "                   (prepared_test['요일구분'] == day_type) & \n",
    "                   (prepared_test['정류장순번'] == station_id)\n",
    "               ].sort_values('datetime').reset_index(drop=True)\n",
    "               \n",
    "               # SARIMA 모델 학습 및 예측\n",
    "               model = SARIMAX(train_station['재차인원'],\n",
    "                             order=(1, 1, 1),\n",
    "                             seasonal_order=(1, 1, 1, 24))\n",
    "               \n",
    "               results = model.fit(disp=False)\n",
    "               forecast = results.get_forecast(steps=len(test_station))\n",
    "               predictions = forecast.predicted_mean\n",
    "               \n",
    "               # 시간대별 평균 예측값 계산\n",
    "               predictions_by_hour = {}\n",
    "               unique_times = test_station['시간'].unique()\n",
    "               pred_splits = np.array_split(predictions, len(unique_times))\n",
    "               \n",
    "               for time, preds in zip(unique_times, pred_splits):\n",
    "                   predictions_by_hour[time] = np.mean(preds) if time in operating_hours else 0\n",
    "               \n",
    "               # 결과 저장\n",
    "               result_dict = {\n",
    "                   '정류장순번': station_id,\n",
    "                   '정류장명': station_name\n",
    "               }\n",
    "               for time in time_columns:\n",
    "                   result_dict[time] = predictions_by_hour.get(time, 0)\n",
    "               \n",
    "               # 요일별 결과 저장\n",
    "               if day_type == '평일':\n",
    "                   weekday_results.append(result_dict)\n",
    "               elif day_type == '토요일':\n",
    "                   saturday_results.append(result_dict)\n",
    "               else:  # 일요일\n",
    "                   sunday_results.append(result_dict)\n",
    "               \n",
    "               # 전체 운행시간대 평가\n",
    "               test_station_operating = test_station[test_station['시간'].isin(operating_hours)].copy()\n",
    "               operating_predictions = np.array([pred for i, pred in enumerate(predictions) \n",
    "                                              if test_station.iloc[i]['시간'] in operating_hours])\n",
    "               \n",
    "               # 첨두시간대 평가\n",
    "               test_station_peak = test_station[test_station['시간'].isin(peak_hours)].copy()\n",
    "               peak_predictions = np.array([pred for i, pred in enumerate(predictions) \n",
    "                                         if test_station.iloc[i]['시간'] in peak_hours])\n",
    "               \n",
    "               # 평가 지표 계산\n",
    "               operating_metrics = calculate_evaluation_metrics(\n",
    "                   test_station_operating['재차인원'].values, \n",
    "                   operating_predictions\n",
    "               )\n",
    "               \n",
    "               peak_metrics = calculate_evaluation_metrics(\n",
    "                   test_station_peak['재차인원'].values, \n",
    "                   peak_predictions\n",
    "               )\n",
    "               \n",
    "               evaluation_results.append({\n",
    "                   '정류장순번': station_id,\n",
    "                   '정류장명': station_name,\n",
    "                   '요일구분': day_type,\n",
    "                   '구분': '전체',\n",
    "                   **operating_metrics\n",
    "               })\n",
    "               \n",
    "               evaluation_results.append({\n",
    "                   '정류장순번': station_id,\n",
    "                   '정류장명': station_name,\n",
    "                   '요일구분': day_type,\n",
    "                   '구분': '첨두',\n",
    "                   **peak_metrics\n",
    "               })\n",
    "               \n",
    "           except Exception as e:\n",
    "               print(f\"오류 발생 - 정류장: {station_id}, 구분: {day_type}\")\n",
    "               print(f\"오류 내용: {str(e)}\")\n",
    "               continue\n",
    "   \n",
    "   # 결과를 DataFrame으로 변환\n",
    "   weekday_df = pd.DataFrame(weekday_results)\n",
    "   saturday_df = pd.DataFrame(saturday_results)\n",
    "   sunday_df = pd.DataFrame(sunday_results)\n",
    "   evaluation_df = pd.DataFrame(evaluation_results)\n",
    "   \n",
    "   # 결과 저장\n",
    "   weekday_df.to_csv('sarima_predictions_weekday.csv', index=False)\n",
    "   saturday_df.to_csv('sarima_predictions_saturday.csv', index=False)\n",
    "   sunday_df.to_csv('sarima_predictions_sunday.csv', index=False)\n",
    "   evaluation_df.to_csv('sarima_evaluation.csv', index=False)\n",
    "   \n",
    "   return weekday_df, saturday_df, sunday_df, evaluation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SARIMA 모델 실행 중...\n",
      "\n",
      "정류장 처리 중... (1/52)\n",
      "\n",
      "정류장 처리 중... (2/52)\n",
      "\n",
      "정류장 처리 중... (3/52)\n",
      "\n",
      "정류장 처리 중... (4/52)\n",
      "\n",
      "정류장 처리 중... (5/52)\n",
      "\n",
      "정류장 처리 중... (6/52)\n",
      "\n",
      "정류장 처리 중... (7/52)\n",
      "\n",
      "정류장 처리 중... (8/52)\n",
      "\n",
      "정류장 처리 중... (9/52)\n",
      "\n",
      "정류장 처리 중... (10/52)\n",
      "\n",
      "정류장 처리 중... (11/52)\n",
      "\n",
      "정류장 처리 중... (12/52)\n",
      "\n",
      "정류장 처리 중... (13/52)\n",
      "\n",
      "정류장 처리 중... (14/52)\n",
      "\n",
      "정류장 처리 중... (15/52)\n",
      "\n",
      "정류장 처리 중... (16/52)\n",
      "\n",
      "정류장 처리 중... (17/52)\n",
      "\n",
      "정류장 처리 중... (18/52)\n",
      "\n",
      "정류장 처리 중... (19/52)\n",
      "\n",
      "정류장 처리 중... (20/52)\n",
      "\n",
      "정류장 처리 중... (21/52)\n",
      "\n",
      "정류장 처리 중... (22/52)\n",
      "\n",
      "정류장 처리 중... (23/52)\n",
      "\n",
      "정류장 처리 중... (24/52)\n",
      "\n",
      "정류장 처리 중... (25/52)\n",
      "\n",
      "정류장 처리 중... (26/52)\n",
      "\n",
      "정류장 처리 중... (27/52)\n",
      "\n",
      "정류장 처리 중... (28/52)\n",
      "\n",
      "정류장 처리 중... (29/52)\n",
      "\n",
      "정류장 처리 중... (30/52)\n",
      "\n",
      "정류장 처리 중... (31/52)\n",
      "\n",
      "정류장 처리 중... (32/52)\n",
      "\n",
      "정류장 처리 중... (33/52)\n",
      "\n",
      "정류장 처리 중... (34/52)\n",
      "\n",
      "정류장 처리 중... (35/52)\n",
      "\n",
      "정류장 처리 중... (36/52)\n",
      "\n",
      "정류장 처리 중... (37/52)\n",
      "\n",
      "정류장 처리 중... (38/52)\n",
      "\n",
      "정류장 처리 중... (39/52)\n",
      "\n",
      "정류장 처리 중... (40/52)\n",
      "\n",
      "정류장 처리 중... (41/52)\n",
      "\n",
      "정류장 처리 중... (42/52)\n",
      "\n",
      "정류장 처리 중... (43/52)\n",
      "\n",
      "정류장 처리 중... (44/52)\n",
      "\n",
      "정류장 처리 중... (45/52)\n",
      "\n",
      "정류장 처리 중... (46/52)\n",
      "\n",
      "정류장 처리 중... (47/52)\n",
      "\n",
      "정류장 처리 중... (48/52)\n",
      "\n",
      "정류장 처리 중... (49/52)\n",
      "\n",
      "정류장 처리 중... (50/52)\n",
      "\n",
      "정류장 처리 중... (51/52)\n",
      "\n",
      "정류장 처리 중... (52/52)\n",
      "\n",
      "분석 완료!\n",
      "결과 파일이 저장되었습니다:\n",
      "- sarima_predictions_weekday.csv\n",
      "- sarima_predictions_saturday.csv\n",
      "- sarima_predictions_sunday.csv\n",
      "- sarima_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "### 3번 블록: 실행 코드\n",
    "\n",
    "# 분석 실행\n",
    "print(\"\\nSARIMA 모델 실행 중...\")\n",
    "weekday_df, saturday_df, sunday_df, evaluation_df = analyze_all_stations(train_data, test_data)\n",
    "\n",
    "print(\"\\n분석 완료!\")\n",
    "print(\"결과 파일이 저장되었습니다:\")\n",
    "print(\"- sarima_predictions_weekday.csv\")\n",
    "print(\"- sarima_predictions_saturday.csv\")\n",
    "print(\"- sarima_predictions_sunday.csv\")\n",
    "print(\"- sarima_evaluation.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
